{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renmeng/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VAL_SPLIT_DATE = '2016-09-15'   # Cutoff date for validation split\n",
    "USE_SEASONAL_FEATURES = True\n",
    "LEARING_RATE = 0.007\n",
    "CV_ONLY = False\n",
    "ADD_OTHER = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties16 = pd.read_csv('../data/properties_2016.csv/properties_2016.csv', low_memory = False)\n",
    "\n",
    "# Number of properties in the zip\n",
    "zip_count = properties16['regionidzip'].value_counts().to_dict()\n",
    "# Number of properties in the city\n",
    "city_count = properties16['regionidcity'].value_counts().to_dict()\n",
    "# Median year of construction by neighborhood\n",
    "medyear = properties16.groupby('regionidneighborhood')['yearbuilt'].aggregate('median').to_dict()\n",
    "# Mean square feet by neighborhood\n",
    "meanarea = properties16.groupby('regionidneighborhood')['calculatedfinishedsquarefeet'].aggregate('mean').to_dict()\n",
    "# Neighborhood latitude and longitude\n",
    "medlat = properties16.groupby('regionidneighborhood')['latitude'].aggregate('median').to_dict()\n",
    "medlong = properties16.groupby('regionidneighborhood')['longitude'].aggregate('median').to_dict()\n",
    "\n",
    "train = pd.read_csv(\"../data/train_2016_v2.csv/train_2016_v2.csv\")\n",
    "for c in properties16.columns:\n",
    "    properties16[c]=properties16[c].fillna(-1)\n",
    "    if properties16[c].dtype == 'object':\n",
    "        lbl = LabelEncoder()\n",
    "        lbl.fit(list(properties16[c].values))\n",
    "        properties16[c] = lbl.transform(list(properties16[c].values))\n",
    "train_df = train.merge(properties16, how='left', on='parcelid')\n",
    "#2016-09-15\n",
    "select_qtr4 = pd.to_datetime(train_df[\"transactiondate\"]) >= VAL_SPLIT_DATE\n",
    "if USE_SEASONAL_FEATURES:\n",
    "    basedate = pd.to_datetime('2015-11-15').toordinal()\n",
    "    \n",
    "citystd = train_df[~select_qtr4].groupby('regionidcity')['logerror'].aggregate(\"std\").to_dict()\n",
    "zipstd = train_df[~select_qtr4].groupby('regionidzip')['logerror'].aggregate(\"std\").to_dict()\n",
    "hoodstd = train_df[~select_qtr4].groupby('regionidneighborhood')['logerror'].aggregate(\"std\").to_dict()\n",
    "\n",
    "\n",
    "        \n",
    "dropvars = ['airconditioningtypeid', 'buildingclasstypeid',\n",
    "            'buildingqualitytypeid', 'regionidcity']\n",
    "droptrain = ['parcelid', 'logerror', 'transactiondate']\n",
    "droptest = ['ParcelId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train.merge(properties16, how='left', on='parcelid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90275, 60)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_features_2(df):\n",
    "    cols = ['parcelid','logerror', 'transactiondate', 'bathroomcnt', 'bedroomcnt', 'calculatedfinishedsquarefeet', 'finishedsquarefeet12', 'lotsizesquarefeet',\\\n",
    "             'roomcnt', 'fips', 'latitude', 'longitude', 'propertycountylandusecode', 'propertylandusetypeid', 'rawcensustractandblock', 'regionidcounty', \\\n",
    "           'regionidcity', 'regionidzip', 'regionidneighborhood',  'yearbuilt', 'taxvaluedollarcnt', 'structuretaxvaluedollarcnt', 'landtaxvaluedollarcnt', \\\n",
    "           'taxamount', 'assessmentyear']\n",
    "    df = df[cols]\n",
    "    df['N-zip_count'] = df['regionidzip'].map(zip_count)\n",
    "    # Number of properties in the city\n",
    "    df['N-city_count'] = df['regionidcity'].map(city_count)\n",
    "    # Does property have a garage, pool or hot tub and AC?\n",
    "     # Mean square feet of neighborhood properties\n",
    "    df['mean_area'] = df['regionidneighborhood'].map(meanarea)\n",
    "    # Median year of construction of neighborhood properties\n",
    "    df['med_year'] = df['regionidneighborhood'].map(medyear)\n",
    "    # Neighborhood latitude and longitude\n",
    "    df['med_lat'] = df['regionidneighborhood'].map(medlat)\n",
    "    df['med_long'] = df['regionidneighborhood'].map(medlong)\n",
    "    df['hood_std'] = df['regionidneighborhood'].map(hoodstd)\n",
    "\n",
    "    df['zip_std'] = df['regionidzip'].map(zipstd)\n",
    "    df['city_std'] = df['regionidcity'].map(citystd)\n",
    "    df['cos_season'] = ( (pd.to_datetime(df['transactiondate']).apply(lambda x: x.toordinal()-basedate)) * \\\n",
    "                             (2*np.pi/365.25) ).apply(np.cos)\n",
    "    df['sin_season'] = ( (pd.to_datetime(df['transactiondate']).apply(lambda x: x.toordinal()-basedate)) * \\\n",
    "                             (2*np.pi/365.25) ).apply(np.sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ADD_OTHER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'parcelid', u'logerror', u'transactiondate', u'airconditioningtypeid',\n",
       "       u'architecturalstyletypeid', u'basementsqft', u'bathroomcnt',\n",
       "       u'bedroomcnt', u'buildingclasstypeid', u'buildingqualitytypeid',\n",
       "       u'calculatedbathnbr', u'decktypeid', u'finishedfloor1squarefeet',\n",
       "       u'calculatedfinishedsquarefeet', u'finishedsquarefeet12',\n",
       "       u'finishedsquarefeet13', u'finishedsquarefeet15',\n",
       "       u'finishedsquarefeet50', u'finishedsquarefeet6', u'fips',\n",
       "       u'fireplacecnt', u'fullbathcnt', u'garagecarcnt', u'garagetotalsqft',\n",
       "       u'hashottuborspa', u'heatingorsystemtypeid', u'latitude', u'longitude',\n",
       "       u'lotsizesquarefeet', u'poolcnt', u'poolsizesum', u'pooltypeid10',\n",
       "       u'pooltypeid2', u'pooltypeid7', u'propertycountylandusecode',\n",
       "       u'propertylandusetypeid', u'propertyzoningdesc',\n",
       "       u'rawcensustractandblock', u'regionidcity', u'regionidcounty',\n",
       "       u'regionidneighborhood', u'regionidzip', u'roomcnt', u'storytypeid',\n",
       "       u'threequarterbathnbr', u'typeconstructiontypeid', u'unitcnt',\n",
       "       u'yardbuildingsqft17', u'yardbuildingsqft26', u'yearbuilt',\n",
       "       u'numberofstories', u'fireplaceflag', u'structuretaxvaluedollarcnt',\n",
       "       u'taxvaluedollarcnt', u'assessmentyear', u'landtaxvaluedollarcnt',\n",
       "       u'taxamount', u'taxdelinquencyflag', u'taxdelinquencyyear',\n",
       "       u'censustractandblock'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "JOIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_SEASONAL_FEATURES = True\n",
    "JOIN = True\n",
    "DELETE = True\n",
    "DUMMY = True\n",
    "MISSING = False\n",
    "TEST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('../data/sample_submission.csv', low_memory = False)\n",
    "\n",
    "\n",
    "droptest += ['transactiondate']\n",
    "\n",
    "test_df = pd.merge( sample_submission[['ParcelId']], \n",
    "                        properties16.rename(columns = {'parcelid': 'ParcelId'}), \n",
    "                        how = 'left', on = 'ParcelId' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df['transactiondate'] = '2016-10-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "# 中位数\n",
    "def mode_function(df):\n",
    "    counts = mode(df)\n",
    "    return counts[0][0]\n",
    "def calculate_features(df):\n",
    "    \n",
    "    if USE_SEASONAL_FEATURES:\n",
    "        df['cos_season'] = ( (pd.to_datetime(df['transactiondate']).apply(lambda x: x.toordinal()-basedate)) * \\\n",
    "                             (2*np.pi/365.25) ).apply(np.cos)\n",
    "        df['sin_season'] = ( (pd.to_datetime(df['transactiondate']).apply(lambda x: x.toordinal()-basedate)) * \\\n",
    "                             (2*np.pi/365.25) ).apply(np.sin)\n",
    "    # Number of properties in the zip\n",
    "#     df['N-zip_count'] = df['regionidzip'].map(zip_count)\n",
    "#     Number of properties in the city\n",
    "#     df['N-city_count'] = df['regionidcity'].map(city_count)\n",
    "#     Does property have a garage, pool or hot tub and AC?\n",
    "#     df['N-GarPoolAC'] = ((df['garagecarcnt']>0) & \\\n",
    "#                          (df['pooltypeid10']>0) & \\\n",
    "#                          (df['airconditioningtypeid']!=5))*1 \n",
    "\n",
    "    # More features\n",
    "    # Mean square feet of neighborhood properties\n",
    "#     df['mean_area'] = df['regionidneighborhood'].map(meanarea)\n",
    "#     Median year of construction of neighborhood properties\n",
    "#     df['med_year'] = df['regionidneighborhood'].map(medyear)\n",
    "#     Neighborhood latitude and longitude\n",
    "#     df['med_lat'] = df['regionidneighborhood'].map(medlat)\n",
    "#     df['med_long'] = df['regionidneighborhood'].map(medlong)\n",
    "\n",
    "#     df['zip_std'] = df['regionidzip'].map(zipstd)\n",
    "#     df['city_std'] = df['regionidcity'].map(citystd)\n",
    "#     df['hood_std'] = df['regionidneighborhood'].map(hoodstd)\n",
    "    \n",
    "    if JOIN:\n",
    "        tmp_log = df.groupby('regionidzip')['logerror'].agg([('mean_',np.mean),\n",
    "                                                    ('std_',np.std),('count_', 'count')]).reset_index()\n",
    "        df = pd.merge(df, tmp_log, on=['regionidzip'], how='left')\n",
    "        \n",
    "        tmp = df.groupby('regionidzip')['yearbuilt'].agg([('mean_year',np.mean),\n",
    "                                                    ('std_year',np.std)]).reset_index()\n",
    "        df = pd.merge(df, tmp, on=['regionidzip'], how='left')\n",
    "        \n",
    "        tmp = df.groupby('regionidzip')['latitude'].agg([('mean_latitude',np.mean),\n",
    "                                                    ('std_latitude',np.std), ('median_latitude', np.median)]).reset_index()\n",
    "        df = pd.merge(df, tmp, on=['regionidzip'], how='left')\n",
    "        \n",
    "        tmp = df.groupby('regionidzip')['longitude'].agg([('mean_longitude',np.mean),\n",
    "                                                    ('std_longitude',np.std), ('median_longitude', np.median)]).reset_index()\n",
    "        df = pd.merge(df, tmp, on=['regionidzip'], how='left')\n",
    "        \n",
    "        \n",
    "        tmp = df.groupby('regionidzip')['rawcensustractandblock'].agg([('mean_census',np.mean),\n",
    "                                                    ('std_census',np.std)]).reset_index()\n",
    "        df = pd.merge(df, tmp, on=['regionidzip'], how='left')\n",
    "        \n",
    "        tmp = df.groupby('regionidzip')['taxamount'].agg([('mean_tax',np.mean),('max_tax', np.max), ('min_tax', np.min),\n",
    "                                                    ('std_tax',np.std), ('mode_tax', mode_function), ('median_tax',np.median)]).reset_index()\n",
    "        df = pd.merge(df, tmp, on=['regionidzip'], how='left')\n",
    "        \n",
    "        tmp = df.groupby('regionidzip')['cos_season'].agg([('mean_season',np.mean),\n",
    "                                                    ('std_season',np.std)]).reset_index()\n",
    "        df = pd.merge(df, tmp, on=['regionidzip'], how='left')\n",
    "        \n",
    "#         ###\n",
    "        \n",
    "        tmp = df.groupby('regionidcity')['logerror'].agg([('mean_city',np.mean),\n",
    "                                                    ('std_city',np.std),('count_city', 'count')]).reset_index()\n",
    "        df = pd.merge(df, tmp, on=['regionidcity'], how='left')\n",
    "        \n",
    "#         tmp = df.groupby('regionidcity')['yearbuilt'].agg([('mean_city_year',np.mean),\n",
    "#                                                     ('std_city_year',np.std)]).reset_index()\n",
    "#         df = pd.merge(df, tmp, on=['regionidcity'], how='left')\n",
    "        \n",
    "#         tmp = df.groupby('regionidcity')['latitude'].agg([('mean_city_latitude',np.mean),\n",
    "#                                                     ('std_city_latitude',np.std), ('median_city_latitude', np.median)]).reset_index()\n",
    "#         df = pd.merge(df, tmp, on=['regionidcity'], how='left')\n",
    "#         tmp = df.groupby('regionidcity')['longitude'].agg([('mean_city_longitude',np.mean),\n",
    "#                                                     ('std_city_longitude',np.std), ('median_city_longitude', np.median)]).reset_index()\n",
    "#         df = pd.merge(df, tmp, on=['regionidcity'], how='left')\n",
    "        \n",
    "        ###\n",
    "        \n",
    "        tmp = df.groupby('propertylandusetypeid')['logerror'].agg([('mean_land',np.mean),\n",
    "                                                    ('std_land',np.std),('count_land', 'count')]).reset_index()\n",
    "        df = pd.merge(df, tmp, on=['propertylandusetypeid'], how='left')\n",
    "        del df['propertylandusetypeid']\n",
    "        \n",
    "        tmp = df.groupby('regionidzip')['std_land'].agg([('mean_std_land',np.mean),\n",
    "                                                    ('std_std_land',np.std)]).reset_index()\n",
    "        df = pd.merge(df, tmp, on=['regionidzip'], how='left')\n",
    "        \n",
    "        \n",
    "        ###\n",
    "        \n",
    "        tmp = df.groupby('regionidneighborhood')['logerror'].agg([('mean_nei',np.mean),\n",
    "                                                    ('std_nei',np.std),('count_nei', 'count')]).reset_index()\n",
    "        df = pd.merge(df, tmp, on=['regionidneighborhood'], how='left')\n",
    "        \n",
    "        ##\n",
    "        \n",
    "        tmp = df.groupby('regionidcounty')['logerror'].agg([('mean_county',np.mean),\n",
    "                                                    ('std_county',np.std),('count_county', 'count')]).reset_index()\n",
    "        df = pd.merge(df, tmp, on=['regionidcounty'], how='left')\n",
    "        if DELETE:\n",
    "            del df['regionidzip']\n",
    "            del df['regionidneighborhood']\n",
    "            del df['regionidcounty']\n",
    "#             del df['regionidcity']\n",
    "        print df.shape\n",
    "\n",
    "    \n",
    "    if ADD_OTHER:\n",
    "        #life of property\n",
    "        df['N-life'] = 2018 - df['yearbuilt']\n",
    "        #Ratio of tax of property over parcel\n",
    "        df['N-ValueRatio'] = df['taxvaluedollarcnt']/df['taxamount']\n",
    "\n",
    "        #TotalTaxScore\n",
    "        df['N-TaxScore'] = df['taxvaluedollarcnt']*df['taxamount']\n",
    "\n",
    "        #polnomials of tax delinquency year\n",
    "        df[\"N-taxdelinquencyyear-2\"] = df[\"taxdelinquencyyear\"] ** 2\n",
    "        df[\"N-taxdelinquencyyear-3\"] = df[\"taxdelinquencyyear\"] ** 3\n",
    "\n",
    "        #Length of time since unpaid taxes\n",
    "        df['N-life2'] = 2018 - df['taxdelinquencyyear']\n",
    "\n",
    "        #error in calculation of the finished living area of home\n",
    "        df['N-LivingAreaError'] = df['calculatedfinishedsquarefeet']/df['finishedsquarefeet12']\n",
    "\n",
    "        #proportion of living area\n",
    "        df['N-LivingAreaProp'] = df['calculatedfinishedsquarefeet']/df['lotsizesquarefeet']\n",
    "        df['N-LivingAreaProp2'] = df['finishedsquarefeet12']/df['finishedsquarefeet15']\n",
    "\n",
    "        #Amout of extra space\n",
    "        df['N-ExtraSpace'] = df['lotsizesquarefeet'] - df['calculatedfinishedsquarefeet'] \n",
    "        df['N-ExtraSpace-2'] = df['finishedsquarefeet15'] - df['finishedsquarefeet12'] \n",
    "\n",
    "        #Total number of rooms\n",
    "        df['N-TotalRooms'] = df['bathroomcnt']*df['bedroomcnt']\n",
    "\n",
    "        #Average room size\n",
    "        df['N-AvRoomSize'] = df['calculatedfinishedsquarefeet']/df['roomcnt'] \n",
    "\n",
    "        # Number of Extra rooms\n",
    "        df['N-ExtraRooms'] = df['roomcnt'] - df['N-TotalRooms'] \n",
    "\n",
    "        #Ratio of the built structure value to land area\n",
    "        df['N-ValueProp'] = df['structuretaxvaluedollarcnt']/df['landtaxvaluedollarcnt']\n",
    "\n",
    "        #Does property have a garage, pool or hot tub and AC?\n",
    "\n",
    "        df[\"N-location\"] = df[\"latitude\"] + df[\"longitude\"]\n",
    "        df[\"N-location-2\"] = df[\"latitude\"]*df[\"longitude\"]\n",
    "        df[\"N-location-2round\"] = df[\"N-location-2\"].round(-4)\n",
    "\n",
    "        df[\"N-latitude-round\"] = df[\"latitude\"].round(-4)\n",
    "        df[\"N-longitude-round\"] = df[\"longitude\"].round(-4)\n",
    "        \n",
    "        #Indicator whether it has AC or not\n",
    "        df['N-ACInd'] = (df['airconditioningtypeid']!=5)*1\n",
    "\n",
    "        #Indicator whether it has Heating or not \n",
    "        df['N-HeatInd'] = (df['heatingorsystemtypeid']!=13)*1\n",
    "\n",
    "        #There's 25 different property uses - let's compress them down to 4 categories\n",
    "#         df['N-PropType'] = df.propertylandusetypeid.replace({31 : \"Mixed\", 46 : \"Other\", 47 : \"Mixed\", 246 : \"Mixed\", 247 : \"Mixed\", 248 : \"Mixed\", 260 : \"Home\", 261 : \"Home\", 262 : \"Home\", 263 : \"Home\", 264 : \"Home\", 265 : \"Home\", 266 : \"Home\", 267 : \"Home\", 268 : \"Home\", 269 : \"Not Built\", 270 : \"Home\", 271 : \"Home\", 273 : \"Home\", 274 : \"Other\", 275 : \"Home\", 276 : \"Home\", 279 : \"Home\", 290 : \"Not Built\", 291 : \"Not Built\" })\n",
    "        #polnomials of the variable\n",
    "        df[\"N-structuretaxvaluedollarcnt-2\"] = df[\"structuretaxvaluedollarcnt\"] ** 2\n",
    "        df[\"N-structuretaxvaluedollarcnt-3\"] = df[\"structuretaxvaluedollarcnt\"] ** 3\n",
    "\n",
    "        #Average structuretaxvaluedollarcnt by city\n",
    "        group = df.groupby('regionidcity')['structuretaxvaluedollarcnt'].aggregate('mean').to_dict()\n",
    "        df['N-Avg-structuretaxvaluedollarcnt'] = df['regionidcity'].map(group)\n",
    "\n",
    "        #Deviation away from average\n",
    "        df['N-Dev-structuretaxvaluedollarcnt'] = abs((df['structuretaxvaluedollarcnt'] - df['N-Avg-structuretaxvaluedollarcnt']))/df['N-Avg-structuretaxvaluedollarcnt']\n",
    "    \n",
    "    if MISSING:\n",
    "        miss = ['propertyzoningdesc', 'unitcnt', 'buildingqualitytypeid', \\\n",
    "                'heatingorsystemtypeid', 'regionidneighborhood', 'garagecarcnt', \\\n",
    "                'garagetotalsqft', 'airconditioningtypeid', 'numberofstories',\\\n",
    "                'poolcnt', 'pooltypeid7', 'fireplacecnt', 'threequarterbathnbr',\\\n",
    "                'finishedfloor1squarefeet', 'finishedsquarefeet50',\\\n",
    "                'finishedsquarefeet15', 'yardbuildingsqft17', 'hashottuborspa',\\\n",
    "                'taxdelinquencyyear', 'taxdelinquencyflag', 'pooltypeid10',\\\n",
    "                'pooltypeid2', 'poolsizesum', 'finishedsquarefeet6', 'decktypeid',\\\n",
    "                'buildingclasstypeid', 'finishedsquarefeet13',\\\n",
    "                'typeconstructiontypeid', 'architecturalstyletypeid',\\\n",
    "                'fireplaceflag', 'yardbuildingsqft26', 'basementsqft', 'storytypeid']\n",
    "        for c in miss:\n",
    "            if c in df.columns.values:\n",
    "                del df[c]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90275, 93)\n",
      "(90275, 93)\n",
      "(2985217, 92)\n",
      "Shape valid X: (14304, 86)\n",
      "Shape valid y: (14304,)\n",
      "\n",
      "Full training set after removing outliers, before dropping vars:\n",
      "Shape training set: (88528, 93)\n",
      "\n",
      "Training subset after removing outliers:\n",
      "Shape train X: (74478, 86)\n",
      "Shape train y: (74478,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/renmeng/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:17: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "train_df, df_test = calculate_features(train_df, test_df)\n",
    "print train_df.shape\n",
    "print df_test.shape\n",
    "\n",
    "x_valid = train_df.drop(dropvars+droptrain, axis=1)[select_qtr4]\n",
    "# x_valid = train_df.drop(droptrain, axis=1)[select_qtr4]\n",
    "y_valid = train_df[\"logerror\"].values.astype(np.float32)[select_qtr4]\n",
    "\n",
    "print('Shape valid X: {}'.format(x_valid.shape))\n",
    "print('Shape valid y: {}'.format(y_valid.shape))\n",
    "\n",
    "train_df=train_df[ train_df.logerror > -0.4 ]\n",
    "train_df=train_df[ train_df.logerror < 0.419 ]\n",
    "print('\\nFull training set after removing outliers, before dropping vars:')     \n",
    "print('Shape training set: {}\\n'.format(train_df.shape))\n",
    "\n",
    "train_df=train_df[~select_qtr4]\n",
    "x_train=train_df.drop(dropvars+droptrain, axis=1)\n",
    "# x_train=train_df.drop(droptrain, axis=1)\n",
    "y_train = train_df[\"logerror\"].values.astype(np.float32)\n",
    "y_mean = np.mean(y_train)\n",
    "n_train = x_train.shape[0]\n",
    "print('Training subset after removing outliers:')     \n",
    "print('Shape train X: {}'.format(x_train.shape))\n",
    "print('Shape train y: {}'.format(y_train.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2985217, 86)"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = df_test.drop(dropvars+droptest, axis=1)\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     Does property have a garage, pool or hot tub and AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split feature\n",
    "xgb_params = {  # best as of 2017-09-28 13:20 UTC\n",
    "    'eta': 0.007,\n",
    "    'max_depth': 7, \n",
    "    'subsample': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'lambda': 2.0,\n",
    "    'alpha': 0.8,\n",
    "    'colsample_bytree': 0.3,\n",
    "    'base_score': y_mean,'taxdelinquencyyear'\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dvalid = xgb.DMatrix(x_valid, y_valid)\n",
    "# if not CV_ONLY:\n",
    "#     dtest = xgb.DMatrix(x_test)\n",
    "#     dtest17 = xgb.DMatrix(x_test17)\n",
    "#     del x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "xgb_params = {  # best as of 2017-09-28 13:20 UTC\n",
    "    'eta': 0.007,\n",
    "    'max_depth': 7, \n",
    "    'subsample': 0.6,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'lambda': 5.0,\n",
    "    'alpha': 0.65,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'base_score': y_mean,'taxdelinquencyyear'\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dvalid = xgb.DMatrix(x_valid, y_valid)\n",
    "# if not CV_ONLY:\n",
    "#     dtest = xgb.DMatrix(x_test)\n",
    "#     dtest17 = xgb.DMatrix(x_test17)\n",
    "#     del x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add_other is True\n",
    "xgb_params = {  # best as of 2017-09-28 13:20 UTC\n",
    "    'eta': 0.007,\n",
    "    'max_depth': 8, \n",
    "    'subsample': 0.6,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'mae',\n",
    "    'lambda': 5.0,\n",
    "    'alpha': 0.65,\n",
    "    'colsample_bytree': 0.3,\n",
    "    'base_score': y_mean,'taxdelinquencyyear'\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dvalid = xgb.DMatrix(x_valid, y_valid)\n",
    "# if not CV_ONLY:\n",
    "#     dtest = xgb.DMatrix(x_test)\n",
    "#     dtest17 = xgb.DMatrix(x_test17)\n",
    "#     del x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boosting rounds: 1200\n",
      "Early stoping rounds: 100\n",
      "[0]\ttrain-mae:0.053447\teval-mae:0.065274\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 100 rounds.\n",
      "[100]\ttrain-mae:0.052753\teval-mae:0.064792\n",
      "[200]\ttrain-mae:0.052301\teval-mae:0.064551\n",
      "[300]\ttrain-mae:0.051967\teval-mae:0.064409\n",
      "[400]\ttrain-mae:0.051686\teval-mae:0.064316\n",
      "[500]\ttrain-mae:0.051449\teval-mae:0.06426\n",
      "[600]\ttrain-mae:0.051235\teval-mae:0.064236\n",
      "[700]\ttrain-mae:0.051029\teval-mae:0.064208\n",
      "[800]\ttrain-mae:0.050846\teval-mae:0.064202\n",
      "Stopping. Best iteration:\n",
      "[739]\ttrain-mae:0.050954\teval-mae:0.064201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_boost_rounds = 1200\n",
    "early_stopping_rounds = 100\n",
    "print('Boosting rounds: {}'.format(num_boost_rounds))\n",
    "print('Early stoping rounds: {}'.format(early_stopping_rounds))\n",
    "evals = [(dtrain,'train'),(dvalid,'eval')]\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=int(num_boost_rounds),\n",
    "                  evals=evals, early_stopping_rounds=early_stopping_rounds, \n",
    "                  verbose_eval=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('taxamount', 4490),\n",
       " ('yearbuilt', 4344),\n",
       " ('calculatedfinishedsquarefeet', 4271),\n",
       " ('structuretaxvaluedollarcnt', 4183),\n",
       " ('cos_season', 4178),\n",
       " ('sin_season', 4144),\n",
       " ('lotsizesquarefeet', 4122),\n",
       " ('landtaxvaluedollarcnt', 4112),\n",
       " ('taxvaluedollarcnt', 3932),\n",
       " ('latitude', 3336),\n",
       " ('longitude', 3312),\n",
       " ('finishedsquarefeet12', 2968),\n",
       " ('mean_', 2001),\n",
       " ('std_', 1819),\n",
       " ('propertyzoningdesc', 1673),\n",
       " ('std_latitude', 1513),\n",
       " ('rawcensustractandblock', 1466),\n",
       " ('mean_std_land', 1416),\n",
       " ('mode_tax', 1403),\n",
       " ('count_', 1321),\n",
       " ('mean_year', 1302),\n",
       " ('med_lat', 1298),\n",
       " ('censustractandblock', 1271),\n",
       " ('mean_city', 1249),\n",
       " ('std_year', 1223),\n",
       " ('std_std_land', 1222),\n",
       " ('std_longitude', 1198),\n",
       " ('mean_tax', 1195),\n",
       " ('med_long', 1189),\n",
       " ('std_census', 1179),\n",
       " ('max_tax', 1172),\n",
       " ('std_tax', 1162),\n",
       " ('min_tax', 1138),\n",
       " ('bedroomcnt', 1136),\n",
       " ('bathroomcnt', 1089),\n",
       " ('median_tax', 1077),\n",
       " ('mean_census', 1035),\n",
       " ('std_city', 947),\n",
       " ('propertycountylandusecode', 856),\n",
       " ('count_city', 811),\n",
       " ('garagetotalsqft', 804),\n",
       " ('finishedsquarefeet15', 800),\n",
       " ('std_city_year', 788),\n",
       " ('mean_longitude', 765),\n",
       " ('mean_latitude', 751),\n",
       " ('mean_city_year', 716),\n",
       " ('calculatedbathnbr', 598),\n",
       " ('poolcnt', 526),\n",
       " ('std_land', 489),\n",
       " ('mean_land', 465),\n",
       " ('median_latitude', 454),\n",
       " ('median_longitude', 432),\n",
       " ('heatingorsystemtypeid', 408),\n",
       " ('count_land', 359),\n",
       " ('roomcnt', 323),\n",
       " ('taxdelinquencyyear', 306),\n",
       " ('fullbathcnt', 301),\n",
       " ('garagecarcnt', 240),\n",
       " ('finishedfloor1squarefeet', 224),\n",
       " ('finishedsquarefeet6', 224),\n",
       " ('numberofstories', 205),\n",
       " ('unitcnt', 200),\n",
       " ('pooltypeid7', 190),\n",
       " ('taxdelinquencyflag', 181),\n",
       " ('yardbuildingsqft17', 179),\n",
       " ('fireplacecnt', 146),\n",
       " ('finishedsquarefeet50', 141),\n",
       " ('hashottuborspa', 125),\n",
       " ('threequarterbathnbr', 108),\n",
       " ('pooltypeid2', 105),\n",
       " ('poolsizesum', 61),\n",
       " ('pooltypeid10', 18),\n",
       " ('decktypeid', 17),\n",
       " ('N-GarPoolAC', 15),\n",
       " ('fips', 14),\n",
       " ('finishedsquarefeet13', 11),\n",
       " ('yardbuildingsqft26', 7),\n",
       " ('architecturalstyletypeid', 4),\n",
       " ('basementsqft', 4),\n",
       " ('typeconstructiontypeid', 3),\n",
       " ('fireplaceflag', 2),\n",
       " ('storytypeid', 2)]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import operator\n",
    "fea = sorted(model.get_fscore().items(), key=operator.itemgetter(1), reverse=True)\n",
    "col = [ele[0] for ele in fea]\n",
    "col = col[:-10]\n",
    "fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train[col]\n",
    "x_valid = x_valid[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('taxamount', 4447),\n",
       " ('landtaxvaluedollarcnt', 4258),\n",
       " ('latitude', 3983),\n",
       " ('lotsizesquarefeet', 3976),\n",
       " ('sin_season', 3905),\n",
       " ('cos_season', 3840),\n",
       " ('yearbuilt', 3822),\n",
       " ('structuretaxvaluedollarcnt', 3751),\n",
       " ('taxvaluedollarcnt', 3719),\n",
       " ('longitude', 3688),\n",
       " ('calculatedfinishedsquarefeet', 3563),\n",
       " ('finishedsquarefeet12', 2687),\n",
       " ('regionidzip', 2595),\n",
       " ('zip_std', 2578),\n",
       " ('N-zip_count', 2523),\n",
       " ('rawcensustractandblock', 2069),\n",
       " ('propertyzoningdesc', 1968),\n",
       " ('mean_area', 1685),\n",
       " ('censustractandblock', 1561),\n",
       " ('N-city_count', 1442),\n",
       " ('med_year', 1420),\n",
       " ('regionidcity', 1419),\n",
       " ('city_std', 1380),\n",
       " ('hood_std', 1279),\n",
       " ('bedroomcnt', 1149),\n",
       " ('med_long', 1111),\n",
       " ('med_lat', 1095),\n",
       " ('regionidneighborhood', 1078),\n",
       " ('propertycountylandusecode', 940),\n",
       " ('bathroomcnt', 927),\n",
       " ('garagetotalsqft', 709),\n",
       " ('finishedsquarefeet15', 708),\n",
       " ('propertylandusetypeid', 640),\n",
       " ('calculatedbathnbr', 518),\n",
       " ('buildingqualitytypeid', 475),\n",
       " ('poolcnt', 474),\n",
       " ('heatingorsystemtypeid', 391),\n",
       " ('airconditioningtypeid', 302),\n",
       " ('taxdelinquencyyear', 290),\n",
       " ('roomcnt', 280),\n",
       " ('fullbathcnt', 270),\n",
       " ('unitcnt', 259),\n",
       " ('finishedsquarefeet6', 247),\n",
       " ('finishedfloor1squarefeet', 230),\n",
       " ('pooltypeid7', 213),\n",
       " ('garagecarcnt', 205),\n",
       " ('numberofstories', 186),\n",
       " ('taxdelinquencyflag', 159),\n",
       " ('hashottuborspa', 154),\n",
       " ('finishedsquarefeet50', 137),\n",
       " ('fireplacecnt', 118),\n",
       " ('threequarterbathnbr', 104),\n",
       " ('yardbuildingsqft17', 95),\n",
       " ('pooltypeid2', 88),\n",
       " ('poolsizesum', 41),\n",
       " ('pooltypeid10', 34),\n",
       " ('fips', 25),\n",
       " ('regionidcounty', 24),\n",
       " ('yardbuildingsqft26', 11),\n",
       " ('decktypeid', 10),\n",
       " ('N-GarPoolAC', 9),\n",
       " ('finishedsquarefeet13', 9),\n",
       " ('typeconstructiontypeid', 7),\n",
       " ('architecturalstyletypeid', 6),\n",
       " ('storytypeid', 2),\n",
       " ('basementsqft', 2)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv(\"../data/train_2016_v2.csv/train_2016_v2.csv\")\n",
    "train = train[['parcelid', 'logerror']]\n",
    "\n",
    "test_df = pd.merge(test_df, train.rename(columns = {'parcelid': 'ParcelId'}), on=['ParcelId'], how='left')\n",
    "\n",
    "test_df['transactiondate'] = '2016-10-31'\n",
    "calculate_features(test_df)\n",
    "x_test = test_df.drop(droptest, axis=1)\n",
    "print('Shape test: {}'.format(x_test.shape))\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "test_10 = model.predict(dtest, ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "test_df = pd.merge( sample_submission[['ParcelId']], \n",
    "                        properties16.rename(columns = {'parcelid': 'ParcelId'}), \n",
    "                        how = 'left', on = 'ParcelId' )\n",
    "test_df['transactiondate'] = '2016-11-30'\n",
    "calculate_features(test_df)\n",
    "x_test = test_df.drop(droptest, axis=1)\n",
    "print('Shape test: {}'.format(x_test.shape))\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "test_11 = model.predict(dtest, ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "test_df = pd.merge( sample_submission[['ParcelId']], \n",
    "                        properties16.rename(columns = {'parcelid': 'ParcelId'}), \n",
    "                        how = 'left', on = 'ParcelId' )\n",
    "test_df['transactiondate'] = '2016-12-31'\n",
    "calculate_features(test_df)\n",
    "x_test = test_df.drop(droptest, axis=1)\n",
    "print('Shape test: {}'.format(x_test.shape))\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "test_12 = model.predict(dtest, ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "\n",
    "\n",
    "output = pd.DataFrame({'ParcelId': sample_submission['ParcelId'].astype(np.int32),\n",
    "           '201610': test_10, '201611': test_11, '201612': test_12,\n",
    "           '201710': test_10, '201711': test_11, '201712': test_12})\n",
    "\n",
    "output.to_csv('../data/feature_64201.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
